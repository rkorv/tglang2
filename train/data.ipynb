{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4078772/3871535822.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  import tqdm.autonotebook as tqdm\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "import tqdm.autonotebook as tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from utils.lang_enum import languages\n",
    "\n",
    "DF_CACHE_PATH = \"../../datasets/cache/all.pickle\"\n",
    "DF_PATHONLY_CACHE_PATH = \"../../datasets/cache/path_only.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FILESIZE = 0.5 * 1024 * 1024 # 1MB\n",
    "\n",
    "def collect_files_content(root_dir, yaml_path):\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        mappings = yaml.safe_load(f)\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for language_tag, language_mapping in tqdm.tqdm(mappings.items()):\n",
    "        for language, extensions in language_mapping.items():\n",
    "            if not isinstance(extensions, list):\n",
    "                extensions = [extensions]\n",
    "\n",
    "            for extension in extensions:\n",
    "                lang_dir = os.path.join(root_dir, language)\n",
    "                if not os.path.exists(lang_dir):\n",
    "                    continue\n",
    "\n",
    "                for dirpath, dirnames, filenames in os.walk(lang_dir, followlinks=True):\n",
    "                    for filename in filenames:\n",
    "                        if extension == \".*\" or filename.endswith(extension):\n",
    "                            try:\n",
    "                                filesize = os.path.getsize(os.path.join(dirpath, filename))\n",
    "                                if filesize < MAX_FILESIZE and filesize > 0:\n",
    "                                    with open(os.path.join(dirpath, filename), 'r') as file:\n",
    "                                        content = file.read()\n",
    "                                        if len(content) > 0:\n",
    "                                            abs_path = os.path.abspath(os.path.join(dirpath, filename))\n",
    "                                            data_list.append((language_tag, language, content, abs_path))\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RosettaCodeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664ef0c7635b49a7bcfcd8bedb02361a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datafile = \"../../datasets/RosettaCodeData/Conf/nlang.yaml\"\n",
    "dataroot = \"../../datasets/RosettaCodeData/Lang\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "rosetta_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "rosetta_df[\"source\"] = \"rosetta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLLDCodeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1f2419b73a44ebb8f0e85b7e198ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datafile = \"../../datasets/deep-learning-lang-detection/data/nlang.yaml\"\n",
    "dataroot = \"../../datasets/deep-learning-lang-detection/data/all\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "dlld_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "dlld_df[\"source\"] = \"dlld\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHubCodeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcbfb5cb75c4a28813283b11bd2b172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datafile = \"../../datasets/github/langs/nlang.yaml\"\n",
    "dataroot = \"../../datasets/github/langs/\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "github_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "github_df[\"source\"] = \"github_langs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430c9e9b4d4e4b8ca301cc632d48a880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datafile = \"../../datasets/github/other/nlang.yaml\"\n",
    "dataroot = \"../../datasets/github/other/\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "github_other_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "github_other_df[\"source\"] = \"github_other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48650bad08a148b886f9a001934108af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datafile = \"../../datasets/github/other_langs/nlang.yaml\"\n",
    "dataroot = \"../../datasets/github/other_langs/\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "github_other_langs_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "github_other_langs_df[\"source\"] = \"github_other_langs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5adb07592d347398d0c740b9cc15fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datafile = \"../../datasets/generated/nlang.yaml\"\n",
    "dataroot = \"../../datasets/generated/\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "gen_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "gen_df[\"source\"] = \"generated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tgdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ae952394da488bbef07b4051b932b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f942d5c2b533480ba95d62706f04e56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datafile = \"../../datasets/tgdataset/nlang.yaml\"\n",
    "dataroot = \"../../datasets/tgdataset/\"\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "tgdataset_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "tgdataset_df[\"source\"] = \"tgdataset\"\n",
    "\n",
    "datafile = \"../../datasets/tgdataset2/nlang.yaml\"\n",
    "dataroot = \"../../datasets/tgdataset2/\"\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "tgdataset2_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "tgdataset2_df[\"source\"] = \"tgdataset2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stackoverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2f875fd01a4444825dff23195a5143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datafile = \"../../datasets/stackoverflow/nlang.yaml\"\n",
    "dataroot = \"../../datasets/stackoverflow/\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "stack_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "stack_df[\"source\"] = \"stackoverflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca28ba02bfb43f2a0718cc1b0b6d5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94ef4cb5a7f49d582b9551cfd3393e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c260aa76434ea0889547b22a7de581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b55097855844619b972ae0989db69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065761bf7f6c4c87893839e7da2fb78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76eaadbd402744ca851329a45f8a9e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tasks\n",
    "datafile = \"../../datasets/llama/tasks/nlang.yaml\"\n",
    "dataroot = \"../../datasets/llama/tasks\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "llama_tasks_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "llama_tasks_df[\"source\"] = \"llama_tasks\"\n",
    "\n",
    "#tasks2\n",
    "datafile = \"../../datasets/llama/tasks2/nlang.yaml\"\n",
    "dataroot = \"../../datasets/llama/tasks2\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "llama_tasks2_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "llama_tasks2_df[\"source\"] = \"llama_tasks2\"\n",
    "\n",
    "#libs\n",
    "datafile = \"../../datasets/llama/libs/nlang.yaml\"\n",
    "dataroot = \"../../datasets/llama/libs\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "llama_libs_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "llama_libs_df[\"source\"] = \"llama_libs\"\n",
    "\n",
    "#keywords\n",
    "datafile = \"../../datasets/llama/keywrods/nlang.yaml\"\n",
    "dataroot = \"../../datasets/llama/keywrods\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "llama_keywords_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "llama_keywords_df[\"source\"] = \"llama_keywords\"\n",
    "\n",
    "#stories\n",
    "datafile = \"../../datasets/llama/stories/nlang.yaml\"\n",
    "dataroot = \"../../datasets/llama/stories\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "llama_stories_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "llama_stories_df[\"source\"] = \"llama_stories\"\n",
    "\n",
    "#shell\n",
    "datafile = \"../../datasets/llama/shell/nlang.yaml\"\n",
    "dataroot = \"../../datasets/llama/shell\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "llama_shell_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "llama_shell_df[\"source\"] = \"llama_shell\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPP_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbeccd2499154698a4b0f482e693122b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datafile = \"../../datasets/CPP_TEST/nlang.yaml\"\n",
    "dataroot = \"../../datasets/CPP_TEST/\"\n",
    "\n",
    "data = collect_files_content(dataroot, datafile)\n",
    "cpp_test_df = pd.DataFrame(data, columns=[\"language_tag\", \"language\", \"code\", \"path\"])\n",
    "cpp_test_df[\"source\"] = \"cpp_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 5,154,973\n",
      "Memory usage: 32.20 GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([rosetta_df, dlld_df, github_df, gen_df, stack_df, github_other_df, github_other_langs_df,\n",
    "                llama_tasks_df, llama_tasks2_df, llama_stories_df, llama_libs_df, llama_keywords_df, llama_shell_df,\n",
    "                cpp_test_df, tgdataset_df, tgdataset2_df], ignore_index=True)\n",
    "print(f\"Number of samples: {len(df):,}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum()/1024/1024/1024:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after slice: 11.63 GB\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "CROP_LEN = int(4096)\n",
    "\n",
    "def crop_text(text):\n",
    "    if len(text) > CROP_LEN:\n",
    "        start = random.randint(0, len(text) - CROP_LEN)\n",
    "        return text[start:start + CROP_LEN]\n",
    "    return text\n",
    "\n",
    "df[\"code\"] = df[\"code\"].apply(crop_text)\n",
    "print(f\"Memory usage after slice: {df.memory_usage(deep=True).sum()/1024/1024/1024:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: rosetta\n",
      "Existing langs: {'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_OTHER', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_NGINX'}\n",
      "\n",
      "Source: dlld\n",
      "Existing langs: {'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_JAVASCRIPT'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_OTHER', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_TYPESCRIPT', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUST'}\n",
      "\n",
      "Source: github_langs\n",
      "Existing langs: {'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_OTHER'}\n",
      "\n",
      "Source: generated\n",
      "Existing langs: {'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_TL'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_OTHER', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "\n",
      "Source: stackoverflow\n",
      "Existing langs: {'TGLANG_LANGUAGE_OTHER'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "\n",
      "Source: github_other\n",
      "Existing langs: {'TGLANG_LANGUAGE_OTHER'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "\n",
      "Source: github_other_langs\n",
      "Existing langs: {'TGLANG_LANGUAGE_OTHER'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "\n",
      "Source: llama_tasks\n",
      "Existing langs: {'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_OTHER', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_TL'}\n",
      "\n",
      "Source: llama_tasks2\n",
      "Existing langs: {'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_TYPESCRIPT', 'TGLANG_LANGUAGE_JAVASCRIPT'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_OTHER', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_PHP'}\n",
      "\n",
      "Source: llama_stories\n",
      "Existing langs: {'TGLANG_LANGUAGE_OTHER'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "\n",
      "Source: llama_libs\n",
      "Existing langs: {'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_TYPESCRIPT', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_JAVASCRIPT'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_OTHER', 'TGLANG_LANGUAGE_NGINX'}\n",
      "\n",
      "Source: llama_keywords\n",
      "Existing langs: {'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_OTHER', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_TL'}\n",
      "\n",
      "Source: llama_shell\n",
      "Existing langs: {'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_SQL'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_OTHER', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "\n",
      "Source: cpp_test\n",
      "Existing langs: {'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_OTHER', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "Missing langs: set()\n",
      "\n",
      "Source: tgdataset\n",
      "Existing langs: {'TGLANG_LANGUAGE_OTHER', 'TGLANG_LANGUAGE_CODE'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "\n",
      "Source: tgdataset2\n",
      "Existing langs: {'TGLANG_LANGUAGE_OTHER', 'TGLANG_LANGUAGE_CODE'}\n",
      "Missing langs: {'TGLANG_LANGUAGE_OBJECTIVE_C', 'TGLANG_LANGUAGE_DOCKER', 'TGLANG_LANGUAGE_CSS', 'TGLANG_LANGUAGE_FUNC', 'TGLANG_LANGUAGE_KOTLIN', 'TGLANG_LANGUAGE_LUA', 'TGLANG_LANGUAGE_PYTHON', 'TGLANG_LANGUAGE_CPLUSPLUS', 'TGLANG_LANGUAGE_SQL', 'TGLANG_LANGUAGE_NGINX', 'TGLANG_LANGUAGE_RUBY', 'TGLANG_LANGUAGE_RUST', 'TGLANG_LANGUAGE_POWERSHELL', 'TGLANG_LANGUAGE_JAVASCRIPT', 'TGLANG_LANGUAGE_C', 'TGLANG_LANGUAGE_JSON', 'TGLANG_LANGUAGE_DART', 'TGLANG_LANGUAGE_JAVA', 'TGLANG_LANGUAGE_HTML', 'TGLANG_LANGUAGE_GO', 'TGLANG_LANGUAGE_SOLIDITY', 'TGLANG_LANGUAGE_SWIFT', 'TGLANG_LANGUAGE_SHELL', 'TGLANG_LANGUAGE_XML', 'TGLANG_LANGUAGE_TL', 'TGLANG_LANGUAGE_PHP', 'TGLANG_LANGUAGE_CSHARP', 'TGLANG_LANGUAGE_TYPESCRIPT'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.lang_enum import languages\n",
    "for s in df.source.unique():\n",
    "    existing_langs = set(df[df.source == s].language_tag.unique().tolist())\n",
    "    missing_langs = set(languages) - existing_langs\n",
    "    print(\"Source:\", s)\n",
    "    print(\"Existing langs:\", existing_langs)\n",
    "    print(\"Missing langs:\", missing_langs)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             language     code     path   source\n",
      "language_tag                                                    \n",
      "TGLANG_LANGUAGE_FUNC             3112     3112     3112     3112\n",
      "TGLANG_LANGUAGE_NGINX            3930     3930     3930     3930\n",
      "TGLANG_LANGUAGE_CODE             3944     3944     3944     3944\n",
      "TGLANG_LANGUAGE_TL              10071    10071    10071    10071\n",
      "TGLANG_LANGUAGE_CSS             20972    20972    20972    20972\n",
      "TGLANG_LANGUAGE_DOCKER          32124    32124    32124    32124\n",
      "TGLANG_LANGUAGE_JAVASCRIPT      43645    43645    43645    43645\n",
      "TGLANG_LANGUAGE_POWERSHELL      46920    46920    46920    46920\n",
      "TGLANG_LANGUAGE_HTML            48679    48679    48679    48679\n",
      "TGLANG_LANGUAGE_LUA             54067    54067    54067    54067\n",
      "TGLANG_LANGUAGE_SQL             54486    54486    54486    54486\n",
      "TGLANG_LANGUAGE_JSON            57001    57001    57001    57001\n",
      "TGLANG_LANGUAGE_SOLIDITY        59440    59440    59440    59440\n",
      "TGLANG_LANGUAGE_PYTHON          64103    64103    64103    64103\n",
      "TGLANG_LANGUAGE_SWIFT           64325    64325    64325    64325\n",
      "TGLANG_LANGUAGE_XML             64730    64730    64730    64730\n",
      "TGLANG_LANGUAGE_SHELL           78891    78891    78891    78891\n",
      "TGLANG_LANGUAGE_DART           101477   101477   101477   101477\n",
      "TGLANG_LANGUAGE_RUST           137864   137864   137864   137864\n",
      "TGLANG_LANGUAGE_RUBY           138318   138318   138318   138318\n",
      "TGLANG_LANGUAGE_OBJECTIVE_C    147268   147268   147268   147268\n",
      "TGLANG_LANGUAGE_PHP            159256   159256   159256   159256\n",
      "TGLANG_LANGUAGE_KOTLIN         160619   160619   160619   160619\n",
      "TGLANG_LANGUAGE_TYPESCRIPT     163450   163450   163450   163450\n",
      "TGLANG_LANGUAGE_JAVA           193213   193213   193213   193213\n",
      "TGLANG_LANGUAGE_C              193567   193567   193567   193567\n",
      "TGLANG_LANGUAGE_CSHARP         234029   234029   234029   234029\n",
      "TGLANG_LANGUAGE_CPLUSPLUS      318690   318690   318690   318690\n",
      "TGLANG_LANGUAGE_GO             356141   356141   356141   356141\n",
      "TGLANG_LANGUAGE_OTHER         2102431  2102431  2102431  2102431\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(\"language_tag\").count().sort_values(by=\"code\", ascending=True).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 5,154,971\n",
      "Saved to ../../datasets/cache/all.pickle\n",
      "Saved to ../../datasets/cache/path_only.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "df[\"code_len\"] = df.code.str.len()\n",
    "\n",
    "with open(\"../../datasets/excluded_paths.txt\", 'r') as f:\n",
    "    excluded_paths = f.read().splitlines()\n",
    "df = df[~df.path.isin(excluded_paths)]\n",
    "print(f\"Number of samples: {len(df):,}\")\n",
    "\n",
    "pickle.dump(df, open(DF_CACHE_PATH, \"wb\"))\n",
    "print(f\"Saved to {DF_CACHE_PATH}\")\n",
    "\n",
    "pickle.dump(df[[\"language_tag\", \"language\", \"path\", \"source\", \"code_len\"]], open(DF_PATHONLY_CACHE_PATH, \"wb\"))\n",
    "print(f\"Saved to {DF_PATHONLY_CACHE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 10.56 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.42it/s]\n",
      "100%|██████████| 13/13 [00:04<00:00,  2.94it/s]\n",
      "100%|██████████| 28/28 [04:46<00:00, 10.25s/it]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.30it/s]t]\n",
      "100%|██████████| 1/1 [01:44<00:00, 104.05s/it] \n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/it]]\n",
      "100%|██████████| 1/1 [01:55<00:00, 116.00s/it]\n",
      "100%|██████████| 26/26 [00:00<00:00, 29.24it/s]\n",
      "100%|██████████| 7/7 [00:03<00:00,  2.05it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]]\n",
      "100%|██████████| 18/18 [00:00<00:00, 58.23it/s]\n",
      "100%|██████████| 26/26 [00:01<00:00, 23.66it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.88it/s]t]\n",
      "100%|██████████| 29/29 [00:00<00:00, 383.57it/s]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.23s/it]t]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.33s/it]t]\n",
      "100%|██████████| 16/16 [08:57<00:00, 33.59s/it]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "DF_CACHE_PATH = \"../../datasets/cache/all.pickle\"\n",
    "with open(DF_CACHE_PATH, \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "tdf = df.loc[:, [\"language_tag\", \"code\", \"source\"]]\n",
    "print(f\"Memory usage: {tdf.memory_usage(deep=True).sum()/1024/1024/1024:.2f} GB\")\n",
    "\n",
    "root_dir_for_save = \"../../datasets/export\"\n",
    "for s in tqdm.tqdm(df.source.unique(), leave=True):\n",
    "    subdf = df[df.source == s]\n",
    "    source_dir = os.path.join(root_dir_for_save, s)\n",
    "    Path(source_dir).mkdir(parents=True, exist_ok=True)\n",
    "    for lang in tqdm.tqdm(subdf.language_tag.unique(), leave=True):\n",
    "        subsubdf = subdf[subdf.language_tag == lang]\n",
    "        file_save_dir = os.path.join(root_dir_for_save, s, lang)\n",
    "        Path(file_save_dir).mkdir(parents=True, exist_ok=True)\n",
    "        for i, row in subsubdf.iterrows():\n",
    "            with open(os.path.join(file_save_dir, f\"{i}.txt\"), 'w') as f:\n",
    "                f.write(row.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language_tag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_NGINX</th>\n",
       "      <td>3930</td>\n",
       "      <td>3930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_CODE</th>\n",
       "      <td>3944</td>\n",
       "      <td>3944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_FUNC</th>\n",
       "      <td>4853</td>\n",
       "      <td>4853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_TL</th>\n",
       "      <td>11172</td>\n",
       "      <td>11172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_CSS</th>\n",
       "      <td>20972</td>\n",
       "      <td>20972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_DOCKER</th>\n",
       "      <td>32124</td>\n",
       "      <td>32124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_POWERSHELL</th>\n",
       "      <td>46920</td>\n",
       "      <td>46920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_HTML</th>\n",
       "      <td>48679</td>\n",
       "      <td>48679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_JAVASCRIPT</th>\n",
       "      <td>49722</td>\n",
       "      <td>49722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_LUA</th>\n",
       "      <td>54067</td>\n",
       "      <td>54067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_SQL</th>\n",
       "      <td>56816</td>\n",
       "      <td>56816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_JSON</th>\n",
       "      <td>57001</td>\n",
       "      <td>57001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_SOLIDITY</th>\n",
       "      <td>59440</td>\n",
       "      <td>59440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_SWIFT</th>\n",
       "      <td>64325</td>\n",
       "      <td>64325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_XML</th>\n",
       "      <td>64730</td>\n",
       "      <td>64730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_PYTHON</th>\n",
       "      <td>73206</td>\n",
       "      <td>73206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_SHELL</th>\n",
       "      <td>90624</td>\n",
       "      <td>90624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_DART</th>\n",
       "      <td>101477</td>\n",
       "      <td>101477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_RUST</th>\n",
       "      <td>137864</td>\n",
       "      <td>137864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_RUBY</th>\n",
       "      <td>138318</td>\n",
       "      <td>138318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_OBJECTIVE_C</th>\n",
       "      <td>147268</td>\n",
       "      <td>147268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_PHP</th>\n",
       "      <td>159256</td>\n",
       "      <td>159256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_KOTLIN</th>\n",
       "      <td>160619</td>\n",
       "      <td>160619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_TYPESCRIPT</th>\n",
       "      <td>169440</td>\n",
       "      <td>169440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_JAVA</th>\n",
       "      <td>193213</td>\n",
       "      <td>193213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_C</th>\n",
       "      <td>193701</td>\n",
       "      <td>193701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_CSHARP</th>\n",
       "      <td>234029</td>\n",
       "      <td>234029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_CPLUSPLUS</th>\n",
       "      <td>318690</td>\n",
       "      <td>318690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_GO</th>\n",
       "      <td>356141</td>\n",
       "      <td>356141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLANG_LANGUAGE_OTHER</th>\n",
       "      <td>2102430</td>\n",
       "      <td>2102430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                code   source\n",
       "language_tag                                 \n",
       "TGLANG_LANGUAGE_NGINX           3930     3930\n",
       "TGLANG_LANGUAGE_CODE            3944     3944\n",
       "TGLANG_LANGUAGE_FUNC            4853     4853\n",
       "TGLANG_LANGUAGE_TL             11172    11172\n",
       "TGLANG_LANGUAGE_CSS            20972    20972\n",
       "TGLANG_LANGUAGE_DOCKER         32124    32124\n",
       "TGLANG_LANGUAGE_POWERSHELL     46920    46920\n",
       "TGLANG_LANGUAGE_HTML           48679    48679\n",
       "TGLANG_LANGUAGE_JAVASCRIPT     49722    49722\n",
       "TGLANG_LANGUAGE_LUA            54067    54067\n",
       "TGLANG_LANGUAGE_SQL            56816    56816\n",
       "TGLANG_LANGUAGE_JSON           57001    57001\n",
       "TGLANG_LANGUAGE_SOLIDITY       59440    59440\n",
       "TGLANG_LANGUAGE_SWIFT          64325    64325\n",
       "TGLANG_LANGUAGE_XML            64730    64730\n",
       "TGLANG_LANGUAGE_PYTHON         73206    73206\n",
       "TGLANG_LANGUAGE_SHELL          90624    90624\n",
       "TGLANG_LANGUAGE_DART          101477   101477\n",
       "TGLANG_LANGUAGE_RUST          137864   137864\n",
       "TGLANG_LANGUAGE_RUBY          138318   138318\n",
       "TGLANG_LANGUAGE_OBJECTIVE_C   147268   147268\n",
       "TGLANG_LANGUAGE_PHP           159256   159256\n",
       "TGLANG_LANGUAGE_KOTLIN        160619   160619\n",
       "TGLANG_LANGUAGE_TYPESCRIPT    169440   169440\n",
       "TGLANG_LANGUAGE_JAVA          193213   193213\n",
       "TGLANG_LANGUAGE_C             193701   193701\n",
       "TGLANG_LANGUAGE_CSHARP        234029   234029\n",
       "TGLANG_LANGUAGE_CPLUSPLUS     318690   318690\n",
       "TGLANG_LANGUAGE_GO            356141   356141\n",
       "TGLANG_LANGUAGE_OTHER        2102430  2102430"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.groupby(\"language_tag\").count().sort_values(by=\"code\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create df from exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "root_path = \"../../datasets/tmp/export\"\n",
    "\n",
    "data = []\n",
    "for root, dirs, files in os.walk(root_path):\n",
    "    if root[len(root_path):].count(os.sep) == 2:\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                path_parts = root.split(os.sep)\n",
    "                source = path_parts[-2]\n",
    "                tag = path_parts[-1]\n",
    "                absolute_path = os.path.abspath(os.path.join(root, file))\n",
    "                data.append({'source': source, 'language_tag': tag, 'path': absolute_path})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "with open(\"../../datasets/tmp/export.pickle\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate frequency tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "DF_CACHE_PATH = \"../../datasets/cache/all.pickle\"\n",
    "df = pickle.load(open(DF_CACHE_PATH, \"rb\"))\n",
    "iterator = df.code.str.lower().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "import string\n",
    "alphabet = string.ascii_lowercase + string.digits + string.punctuation + string.whitespace\n",
    "\n",
    "new_tokenizer = BertTokenizerFast(\"../../datasets/vocab.txt\", do_lower_case=True).train_new_from_iterator(iterator, vocab_size=5500, limit_alphabet=len(alphabet)+1, initial_alphabet=list(alphabet))\n",
    "print(len(new_tokenizer.vocab))\n",
    "new_tokenizer.save_vocabulary(\"../../datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [13:48<00:00, 28.59s/it]  \n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import utils.lang_enum as lang_enum\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "import re\n",
    "\n",
    "def tokenize_code(code: str) -> List[str]:\n",
    "    return re.findall(r'\\b\\w+\\b', code.lower())\n",
    "\n",
    "def filter_vocab(vocab: Dict[str, int]) -> Dict[str, int]:\n",
    "    vocab = {token: idx for token, idx in vocab.items() if len(token) > 1}\n",
    "    vocab = {token: idx for token, idx in vocab.items() if not token.isdigit()}\n",
    "    return vocab\n",
    "\n",
    "def create_vocabulary(codes: List[str], min_freq: int, top_k: int) -> Dict[str, int]:\n",
    "    token_counts = Counter()\n",
    "    for code in codes:\n",
    "        unique_tokens = set(tokenize_code(code.lower()))\n",
    "        token_counts.update(unique_tokens)\n",
    "    common_tokens = [token for token, count in token_counts.most_common(top_k) if count >= min_freq]\n",
    "    vocabulary = {token: idx for idx, token in enumerate(common_tokens, start=1)}\n",
    "    return vocabulary\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "def create_vocabulary_gpt(codes: List[str], min_freq: int, top_k: int) -> Dict[str, int]:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "    return tokenizer.train_new_from_iterator(codes, vocab_size=top_k).vocab\n",
    "\n",
    "vocabs = {}\n",
    "vocabs_gpt = {}\n",
    "for lang in tqdm.tqdm(lang_enum.languages):\n",
    "    ldf = df[df[\"language_tag\"] == lang]\n",
    "    vocab = create_vocabulary(ldf.code.str.lower().to_list(), int(len(ldf)*0.001), 500)\n",
    "    vocabs[lang] = filter_vocab(vocab)\n",
    "\n",
    "    size = 1000 if lang == \"TGLANG_LANGUAGE_OTHER\" else 600\n",
    "    vocab_gpt = create_vocabulary_gpt(ldf.code.str.lower().to_list(), int(len(ldf)*0.001), size)\n",
    "    vocabs_gpt[lang] = filter_vocab(vocab_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "res_vocabs = {lang: list(d.keys()) for lang, d in vocabs.items()}\n",
    "with open(\"../../datasets/vocabs.json\", \"w\") as f:\n",
    "    json.dump(res_vocabs, f)\n",
    "\n",
    "res_vocabs_gpt = {lang: list(d.keys()) for lang, d in vocabs_gpt.items()}\n",
    "with open(\"../../datasets/vocabs_gpt2.json\", \"w\") as f:\n",
    "    json.dump(res_vocabs_gpt, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6144\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import utils.lang_constructs\n",
    "with open(\"../../datasets/vocabs.json\", \"r\") as f:\n",
    "    vocabs = json.load(f)\n",
    "with open(\"../../datasets/vocabs_gpt2.json\", \"r\") as f:\n",
    "    vocabs_gpt2 = json.load(f)\n",
    "for l in vocabs:\n",
    "    vocabs_gpt2[l] = [t[1:] if t.startswith(\"Ġ\") else t for t in vocabs_gpt2[l]]\n",
    "\n",
    "with open(\"../../datasets/old_vocabulary.txt\", \"r\") as f:\n",
    "    old_vocab = f.read().split(\"\\n\")\n",
    "\n",
    "with open(\"../../datasets/vocab.txt\", \"r\") as f:\n",
    "    bert_vocab = f.read().split(\"\\n\")\n",
    "bert_vocab = [t for t in bert_vocab if len(t) > 1 and \"#\" not in t and t.isascii()]\n",
    "\n",
    "libs_kws = []\n",
    "for vs in utils.lang_constructs.lang_libs.values():\n",
    "    for v in vs:\n",
    "        name, acronym, libs = v\n",
    "        if name.isalpha():\n",
    "            libs_kws.append(name)\n",
    "        libs_kws.append(acronym)\n",
    "        libs_kws += libs\n",
    "\n",
    "kws = utils.lang_constructs.lang_keywords\n",
    "\n",
    "all_keywords = bert_vocab\n",
    "for lang, vocab in vocabs.items():\n",
    "    all_keywords += vocab\n",
    "for lang, vocab in kws.items():\n",
    "    all_keywords += vocab\n",
    "all_keywords += old_vocab\n",
    "all_keywords += libs_kws\n",
    "\n",
    "def clean(kws):\n",
    "    kws = [kw for kw in kws if len(kw) > 1]\n",
    "    kws = [kw for kw in kws if len(kw) < 30]\n",
    "    kws = [kw for kw in kws if not kw.isdigit()]\n",
    "    kws = list(set(kws))\n",
    "    kws = [kw for kw in kws if kw != \"\"]\n",
    "    return kws\n",
    "\n",
    "def remove_prefix(kws, prefix, new_vals=None):\n",
    "    kws = [kw if not kw.startswith(prefix) else kw[len(prefix):] for kw in kws]\n",
    "    if new_vals is not None:\n",
    "        kws += new_vals\n",
    "\n",
    "    return clean(kws)\n",
    "\n",
    "def split_by(kws, sep, min_len=0):\n",
    "    contain_spaces = []\n",
    "    rest = []\n",
    "\n",
    "    for kw in kws:\n",
    "        if len(kw) < min_len:\n",
    "            continue\n",
    "\n",
    "        if sep in kw:\n",
    "            contain_spaces.append(kw)\n",
    "\n",
    "    rest = [kw for kw in kws if kw not in contain_spaces]\n",
    "    for kw in contain_spaces:\n",
    "        rest += kw.split(sep)\n",
    "\n",
    "    return clean(rest)\n",
    "\n",
    "\n",
    "all_keywords = [kw.lower() for kw in all_keywords]\n",
    "all_keywords = [kw for kw in all_keywords if kw.isascii()]\n",
    "all_keywords = split_by(all_keywords, \" \")\n",
    "all_keywords = split_by(all_keywords, \"\\n\")\n",
    "all_keywords = split_by(all_keywords, \"\\t\")\n",
    "all_keywords = split_by(all_keywords, \"\\\\\", min_len=5)\n",
    "all_keywords = split_by(all_keywords, \"/\", min_len=5)\n",
    "all_keywords = split_by(all_keywords, \".\", min_len=5)\n",
    "all_keywords = split_by(all_keywords, \"_\", min_len=5)\n",
    "all_keywords = split_by(all_keywords, \":\", min_len=5)\n",
    "all_keywords = split_by(all_keywords, \"()\", min_len=5)\n",
    "all_keywords = split_by(all_keywords, \"}\", min_len=5)\n",
    "all_keywords = split_by(all_keywords, \"{\", min_len=5)\n",
    "all_keywords = split_by(all_keywords, \"::\")\n",
    "all_keywords += [\"::\", \"std::\", \"dart::\", \"()\", \"-i\", \"##.h\"]\n",
    "\n",
    "all_keywords = [kw for kw in all_keywords if len(kw) < 15]\n",
    "all_keywords = [kw for kw in all_keywords if len(re.findall(r\"\\d\", kw)) < 2]\n",
    "\n",
    "all_keywords = remove_prefix(all_keywords, \"0x\", [\"0x\"])\n",
    "all_keywords = remove_prefix(all_keywords, \"0b\", [\"0b\"])\n",
    "all_keywords = clean(all_keywords)\n",
    "all_keywords = list(set(all_keywords))\n",
    "print(len(all_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./vocabulary.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(all_keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm.autonotebook as tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "def read_files_to_string(path, splitter='\\n'):\n",
    "    content = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            with open(filepath, 'r', errors='replace') as file:\n",
    "                content.append(file.read())\n",
    "\n",
    "    all_content = splitter.join(content)\n",
    "    no_empty_lines = splitter.join([line for line in all_content.split(splitter) if line.strip()])\n",
    "\n",
    "    return no_empty_lines.split(splitter)\n",
    "\n",
    "def generate_random_files(strings, output_path, num_files, k=100, header=\"\"):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    for i in tqdm.tqdm(range(num_files)):\n",
    "        random_selection = random.choices(strings, k=k)\n",
    "\n",
    "        file_name = f\"output_file_{i+1}.txt\"\n",
    "        file_path = os.path.join(output_path, file_name)\n",
    "\n",
    "        with open(file_path, 'w') as file:\n",
    "            if header:\n",
    "                file.write(header + \"\\n\")\n",
    "            for line in random_selection:\n",
    "                file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TL Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1051/10000 [00:00<00:00, 10502.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 11532.93it/s]\n"
     ]
    }
   ],
   "source": [
    "path_to_folder = '../../datasets/downloaded_files/TL Type Language'\n",
    "result = read_files_to_string(path_to_folder)\n",
    "\n",
    "output_path = '../../datasets/generated/TL Type Language'\n",
    "generate_random_files(result, output_path, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate FUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 8415.59it/s]\n"
     ]
    }
   ],
   "source": [
    "path_to_folder = '../../datasets/generated/custom_func'\n",
    "result = read_files_to_string(path_to_folder, splitter='\\n---')\n",
    "\n",
    "output_path = '../../datasets/generated/FUNC contract'\n",
    "generate_random_files(result, output_path, 3000, k=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
