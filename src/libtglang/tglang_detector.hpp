#pragma once

#include <iostream>
#include <vector>

#include <model_meta.hpp> // Generated by python script

#include "tglang.h"
#include "tglang_preprocessor.hpp"

#ifdef INFERENCE_TFLITE
#include "inference/tflite.hpp"
#endif

#ifdef INFERENCE_ONNX
#include "inference/onnx.hpp"
#endif

class TglangDetector
{
    TglangPreprocessor preprocessor;
    TglangModelInference model;

public:
    TglangDetector() {}

    enum TglangLanguage detect_programming_language(const char *text)
    {
        std::vector<det_int_t> encoded_text, naming_types, group_types, lines_num, positions_ids;

        /* Encode input text to tokens */
        this->preprocessor.preprocess(text, encoded_text, naming_types, group_types, lines_num, positions_ids);
        if (encoded_text.size() == 0)
            return TGLANG_LANGUAGE_OTHER;

        return (enum TglangLanguage)model.forward(encoded_text, naming_types, group_types, lines_num, positions_ids);
    }
};
